## Nice bar plot of grouping benchmark timings based on Matt Dowle scripts from 2014
## https://github.com/h2oai/db-benchmark/commit/fce1b8c9177afb49471fcf483a438f619f1a992b
## Original grouping benchmark can be found in: https://github.com/Rdatatable/data.table/wiki/Benchmarks-:-Grouping

source("helpers.R") # for solution date based on git sha from github repositories, if no git revision available then hardcoded dictionary
stopifnot(sapply(c("curl","jsonlite"), requireNamespace, quietly=TRUE)) # used for lookup date based on git
library(data.table)
if (!capabilities()[["X11"]] && capabilities()[["cairo"]]) options(bitmapType="cairo") # fix for R compiled with-x=no with-cairo=yes

solution.colors = rbindlist(list(
  list(solution="dplyr", colmain="red", collight="#FF7777"),
  list(solution="data.table", "blue", "#7777FF"),
  list(solution="pandas", "green4", "#77FF77"),
  list(solution="pydatatable", "darkorange", "orange"),
  list(solution="spark", "#8000FFFF", "#CC66FF"),
  list(solution="dask", "slategrey", "lightgrey"),
  list(solution="juliadf", "deepskyblue", "darkturquoise")
))

format_comma = function(x) format(as.integer(signif(x,4)), big.mark=",")

get_xlab_values = function(x) {
  at = pretty(x, 10)
  at[at!=0]
}

get_xlab_timescale = function(x) {
  if (x > 2*60*60) {
    timescale = 3600
    xlab = "Hours"
  } else if (x > 120) {
    timescale = 60
    xlab = "Minutes"
  } else {
    timescale = 1
    xlab = "Seconds"
  }
  setNames(timescale, xlab)
}

textBG = function(x, y, txt, w, ...) {
  txtw = strwidth(txt, ...); txth = strheight(txt, ...);
  txty = y-2*w;  # w from calling scope above
  rect(x, txty, x+txtw, txty+1.8*txth, col="white", border=NA)
  text(x, y, txt, adj=c(0, 0.7), ...)
}

if (!interactive()) browser = function(...) stop("some new exception in timings data to handle, go interactive mode")

# .nrow default Inf, numeric to filter out timingsto single in_rows, Inf will results to use maximum in_rows from timings
# task default "groupby", character scalar to filter out timings to single task, currently benchplot is used only for groupby task
# timings data.table of timings, structure as generated by `run.sh` script
# code list of syntax for solutions grouped by questions so syntax can be plotted next to the bars
# colors data.table of solutions and colors assigned to them
# cutoff character name of solution to cutoff all longer timings
# cutoff.after numeric default 0.2, to cutoff after 120% percent of timing of solution provided to 'cutoff' argument, provide 0.5 for 150% and so on
# .interactive default interactive(), when TRUE it will print some output to console and open png after finished
# by.nsolutions default FALSE, when TRUE it will generate png filename as 'groupby.[nsolutions].[in_rows].png' so scaling of benchplot can be easily compared for various number of solutions
# fnam fixed filename if do not want to generate from pattern
benchplot = function(.nrow=Inf, task="groupby", data, timings, code, colors, cutoff="spark", cutoff.after=0.2, .interactive=interactive(), by.nsolutions=FALSE, fnam=NULL, path="public/plots") {
  stopifnot(c("task","time_sec_1","time_sec_2","question","solution","in_rows","out_rows","out_cols","version","git","batch") %in% names(timings))
  stopifnot(is.character(task), length(task)==1L, !is.na(task))
  if (!is.data.table(colors)) stop("argument colors must be data.table of solutions and colors assigned to each")
  if (!is.character(cutoff) || length(cutoff)>1) stop("cutoff must be character of length 0 to 1")
  if (missing(code)) stop("provide 'code' argument, list of questions and respective queries in each solution")
  timings.task = unique(timings$task)
  if (length(intersect(timings.task, task))!=1L) stop("there should be only single task to present on benchplot, provide 'task' argument which exists in 'timings' dataset")
  vtask = task
  # filter timings to single task
  timings = timings[task==vtask]
  
  # if no .nrow argument provided then use maximum in_rows in timings
  if (!is.finite(.nrow)) .nrow = timings[, max(as.numeric(in_rows))]
  
  exceptions = TRUE
  if (exceptions) {
    min_versions = timings[as.numeric(in_rows)==min(as.numeric(in_rows)), head(.SD, 1L), "solution", .SDcols=c("version","git","batch")]
  }
  
  # filter timings to single data
  .data = data; rm(data)
  timings = timings[data==.data]
  if (!nrow(timings)) {
    message(sprintf("Nothing to plot for %s %s", task, .data))
    return(invisible(NULL))
  }
  if (uniqueN(timings$in_rows) != 1L) stop("There should be only single 'in_rows' after filtering on 'data'")
  
  questions = unique(na.omit(timings$question)) # NA questions for those who failed
  nquestions = length(questions)
  data = unique(timings$data)
  ndata = length(data)
  if (ndata!=1L) stop("only single 'data' field supported, run benchplot for each 'data'")
  if (exceptions) { # general exception handling
    ex_s = "pydatatable"
    fix_general = timings[solution==ex_s
            ][, c("version","git","time_sec_1","time_sec_2","mem_gb_1","mem_gb_2","chk","chk_time_sec","fun","timestamp_1","timestamp_2","ibatch","batch","solution","script_time_sec","script_start","script_finish","chk_time_sec_1","chk_time_sec_2") := NA
              ][]
    fix_all = rbindlist(lapply(unique(timings$solution), function(s) fix_general[,.SD][, "solution":=s]))
    decode = function(x, y) {nax = is.na(x); x[nax] = y[nax]; x}
    timings = timings[fix_all, on=c("solution","task","data","question","iquestion"), .SD]
    timings[min_versions, on="solution", `:=`(version=decode(version, i.version), git=decode(git, i.git), batch=decode(batch, i.batch))]
    
    timings[is.na(time_sec_2), "time_sec_1" := NA_real_] # if 2 run failed, reset first one
    
    # spark, pandas does not return grouping columns so out_cols measure is incorrect
    timings[solution%in%c("spark","pandas","dask"), "out_cols" := NA_integer_]
  }
  
  solutions = unique(timings$solution)
  nsolutions = length(solutions)
  
  if (length(cutoff) && !cutoff%in%solutions) stop(sprintf("'cutoff' argument used but provided value '%s' is not a solution existing in timing data", cutoff))
  
  # get data size in GB from current directory by filename match
  gb = (if (file.exists(f<-file.path("data", paste(data,"csv",sep=".")))) file.info(f)$size else NA_real_)/1024^3
  
  # keep only required columns
  timings = timings[, .SD, .SDcols=c("time_sec_1","time_sec_2","question","iquestion","solution","in_rows","out_rows","out_cols","version","git","batch")]
  
  if (is.null(fnam)) fnam = paste0(task, if (by.nsolutions) paste0(".", nsolutions) else "", ".", gsub("e[+]0", "E", pretty_sci(.nrow)), ".png")
  if (!is.null(path)) {
    if (!dir.exists(path)) dir.create(path, recursive=TRUE)
    fnam = file.path(path, fnam)
  }
  if (.interactive) cat("Plotting to", fnam, "...\n")
  height = 700+120*nsolutions;
  png(file=fnam, width=800, height=height)

  mar.top = 3.1+nsolutions
  mar.bot = 3.3/nsolutions
  par(mar=c(mar.bot, 1.1, mar.top, 2.1)) # shift to the left: c(bottom, left, top, right)
  
  # veriyfy colors unique and defined for every solution
  stopifnot(colors[, .N==1L, .(solution, colmain, collight)]$V1)
  timings[colors, c("colmain","collight") := list(i.colmain, i.collight), on="solution"]
  stopifnot(timings[is.na(colmain) | is.na(collight), .N==0L])
  
  # cutoff
  .cutoff = cutoff; rm(cutoff)
  timings[, c("cutoff_1","cutoff_2"):=FALSE]
  if (length(.cutoff)) {
    cutoff.time = timings[solution==.cutoff, max(c(time_sec_1, time_sec_2), na.rm=TRUE)]
    cutoff.time.after = cutoff.time * (1+cutoff.after)
    if (is.na(cutoff.time)) stop("cutoff.time value is NA")
    timings[time_sec_1 > cutoff.time.after, "cutoff_1":=TRUE]
    timings[time_sec_2 > cutoff.time.after, "cutoff_2":=TRUE]
  }
  
  # define units of measure on X axis
  timescale = get_xlab_timescale(timings[, max(c(time_sec_1[cutoff_1==FALSE], time_sec_2[cutoff_2==FALSE]), na.rm=TRUE)])
  
  # prepare timings in expected unit of measure
  timings[, bars_1:=time_sec_1/timescale][, cutoff_bars_1:=bars_1][cutoff_1==TRUE, bars_1:=NA_real_]
  timings[, bars_2:=time_sec_2/timescale][, cutoff_bars_2:=bars_2][cutoff_2==TRUE, bars_2:=NA_real_]
  cutoff.bars.after = if (length(.cutoff)) cutoff.time.after/timescale else 0
  
  # X axis values
  x_at = timings[, get_xlab_values(c(bars_1, bars_2, cutoff.bars.after))]
  
  # order for bar horiz=TRUE does first bar from the bottom!
  ans = timings[, .SD][, max_time_sec:=max(c(time_sec_1, time_sec_2)), by=.(solution, question)][order(iquestion, max_time_sec, na.last=FALSE, decreasing=TRUE)]
  
  # use padding to reserve extra space for solution syntax, and top X axis and its labels
  pad = as.vector(sapply(0:4, function(x) c(as.vector(rbind(x*nsolutions + 1:nsolutions, NA)), NA, NA)))
  # get bars coordinates, plot positions only
  tt = barplot(rep(NA_real_, nrow(ans))[pad], horiz=TRUE, xlim=c(0, tail(x_at, 1L)), axes=FALSE)
  
  # we reverse `tt` as horiz=TRUE does first bar from the bottom
  tt = rev(tt)
  # calculate half of bar width used later on in many places
  w = (tt[1]-tt[2])/4
  
  # upper line break to separate legend from timings
  h1 = tt[1]
  abline(h=h1)
  # X axis upper label (seconds, minutes) and values
  ff = if (length(x_at)<=8) TRUE else -1  # ff = first first X axis label overlap
  text(x=x_at[ff], y=h1, labels=format(x_at[ff]), adj=c(0.5, -0.5), cex=1.5, font=2, xpd=NA)
  text(x=0, y=h1, labels=names(timescale), adj=c(0, -0.5), font=2, cex=1.5, xpd=NA)
  
  # bottom horizontal line of X axis
  h2 = tail(tt, 1)-4*w
  abline(h=h2)
  # X axis lower label (seconds/minutes) and values
  text(x=x_at[ff], y=h2, labels=format(x_at[ff]), adj=c(0.5, 1.5), cex=1.5, font=2, xpd=NA)
  text(x=0, y=h2, labels=names(timescale), adj=c(0, 1.5), font=2, cex=1.5, xpd=NA)
  
  space = nsolutions*2 + 2
  # grey horizontal lines separating questions
  abline(h=tt[seq(space+1, by=space, length=4)], col="grey", lwd=2)
  # dotted vertical lines to form grid
  for (at_x in x_at) lines(x=c(at_x, at_x), y=c(h1, h2), col="lightgrey", lwd=2, lty="dotted")
  
  # first run bars according to solutions
  ans[, barplot(cutoff_bars_1[pad], horiz=TRUE, axes=FALSE,
                col=c(colmain,"black")[pad],
                font=2, xpd=NA, add=TRUE)]
  
  # for each question remaining plotting
  for (iq in 1L:nquestions) {
    
    # determine order of solutions according to max time_sec for this question
    q_ord_solutions = ans[iquestion==iq][order(max_time_sec, na.last=TRUE), as.character(solution)]
    stopifnot(length(q_ord_solutions)==nsolutions)
    
    # plot solutions syntax
    for (is in 1L:nsolutions) {
      s = q_ord_solutions[is]
      cod = code[[questions[iq]]][[s]]
      col = colors[s, colmain, on="solution"]
      textBG(0, tt[is*2L+1L+(iq-1)*space], txt=cod, w=w, col=col, font=2)
    }
    
    # plot question headers
    out_rows = ans[iquestion==iq, na.omit(out_rows)]
    if (length(unique(out_rows)) != 1L) stop("out_rows mismatch")
    out_cols = ans[iquestion==iq, na.omit(out_cols)]
    if (length(unique(out_cols)) != 1L) stop("out_cols mismatch")
    textBG(0, tt[2+(iq-1)*space], w=w, font=2, txt=sprintf("Question %s: %s ad hoc groups of %s rows;  result %s x %s", iq, format_comma(out_rows[1L]), format_comma(.nrow/out_rows[1L]), format_comma(out_rows[1L]), out_cols[1L]))
    
    # second timing bars
    for (is in 1L:nsolutions) {
      s = q_ord_solutions[is]
      val = ans[solution==s & iquestion==iq, cutoff_bars_2]
      at = tt[(is+1)*2+(iq-1)*space]
      if (!is.na(val)) {
        rect(0, at-w, val, at+w, col=colors[s, collight, on="solution"], xpd=NA)
      } else { # we should use dictionary here instead of hardcoded
        exception = if (s%in%c("pandas","dask")) "Lack of memory to read data"
        else if (s%in%c("dplyr")) "timeout / Cannot allocate memory"
        else if (s%in%c("data.table")) "timeout / memory monitor OOM"
        else if (s%in%c("juliadf")) "timeout / OutOfMemoryError"
        else "timeout / undefined exception"
        textBG(0, tt[(is+1)*2+(iq-1)*space], txt=exception, w=w, col=colors[s, colmain, on="solution"], font=2)
      }
    }
    
  }
  
  # plot timing values next to each bar
  max_t = ans[, pmax(cutoff_bars_1, cutoff_bars_2)]
  both_t = ans[, paste(unique(round(c(cutoff_bars_1, cutoff_bars_2),2)), collapse="; "), by=c("solution","question")]$V1  # print both runs timings #31 (unless same), round to 2 decimals places to avoid 0.0 cases
  stopifnot(length(max_t)==length(both_t))
  max_t_x_pos = max_t
  if (length(.cutoff) && length(cutoff.i<-which(max_t>cutoff.bars.after))) {
    both_t[cutoff.i] = paste("...", both_t[cutoff.i])
    max_t_x_pos[cutoff.i] = x_at[length(x_at)-2L] #cutoff.bars.after, shifted by 2 x axis ticks to fit values in the plot
  }
  max_t_y_pos = rev(tt)[!is.na(pad)]-w/2
  text(max_t_x_pos, max_t_y_pos, both_t, pos=4, cex=1.25)
  
  # cost per hour
  cph = 0.5 # minimum on graph histories; what people will see if they check
  
  # legend location
  topoffset = nsolutions*5-3
  legend_y = par()$usr[4]+topoffset*w # usr: c(x1, x2, y1, y2)
  
  # legend header
  mtext(sprintf("Input table: %s rows x %s columns ( %s GB )",
                format_comma(.nrow), 9L, # hardcoded number of columns!
                if (!is.na(gb)) { if (gb<1) round(gb, 1) else 5*round(ceiling(gb)/5) } else "NA"),
        line=1.5+nsolutions,
        side=3, cex=1.5, adj=0, font=2)
  # legend first/second timing box
  legend(par()$usr[2], legend_y, pch=22, xpd=NA, xjust=1, bty="n", pt.lwd=1,
         legend=c("First time", "Second time"), pt.cex=c(3.5, 2.5), cex=1.5, pt.bg=colors[solution=="data.table", c(colmain, collight)])
  
  # legend
  ans[, .(total_time_sec = sum(c(time_sec_1, time_sec_2)), # total time of run 1 and run 2 for all questions
          batch=min(batch), version=version[1], git=git[1], colmain=colmain[1]), # batch=min(batch) in case different data tested in different benchmark runs, earliest is taken, as for all runs there should same version so we need a date of earliest run of that version
      keyby="solution"
      ][order(total_time_sec, na.last=TRUE)
        ][, .(leg=sprintf(
        "%s %s  -  %s  -  Total: $%.02f for %s %s",
        if (solution=="pydatatable") "(py)datatable" else if (solution=="juliadf") "DataFrames.jl" else solution, # decode names
        version,
        format(as.Date(as.POSIXct(as.numeric(batch), origin="1970-01-01"))), # solution.date(solution, version, git, only.date=TRUE, use.cache=TRUE),
        cph*total_time_sec/3600, # cost in dollars
        round(total_time_sec/timescale, 0),
        tolower(names(timescale)) # minutes/seconds
      ), colmain=colmain),
      by="solution"
      ][, legend(0, legend_y, pch=22, pt.bg=colmain, bty="n", cex=1.5, pt.cex=3.5,
                 text.font=1, xpd=NA, legend=leg)] -> nul
  
  # footer timestamp of plot gen
  mtext(side=1, line=-1, text=format(Sys.time(), usetz=TRUE), adj=1, outer=TRUE, cex=1)
  # put link to report
  mtext(side=1, line=-1, text=" https://h2oai.github.io/db-benchmark", adj=0, outer=TRUE, cex=1)
  dev.off()
  if (.interactive) system(paste("/usr/bin/xdg-open",fnam), wait=FALSE) else invisible(TRUE)
}

if (dev1<-FALSE) {
  stop("adjust non-max batch only")
  d = fread("time.csv")[!is.na(batch)][batch==max(batch)]
  .nrow=1e9
  # verify scaling across number of solutions
  sols = list(c("data.table","pandas","dplyr"),
              c("data.table","pandas","dplyr","pydatatable"),
              c("data.table","spark","pydatatable","pandas","dplyr"),
              c("data.table","spark","pydatatable","pandas","dplyr","dask"),
              c("data.table","juliadf","dask","spark","pydatatable","pandas","dplyr"))
  for (s in sols) {
    benchplot(.nrow=.nrow, timings=d[solution%in%s], code=groupby.code, colors=solution.colors, .interactive=FALSE, by.nsolutions=TRUE)
  }
} else if (dev2<-FALSE) {
  source("report.R")
  source("report-code.R")
  ld = time_logs()
  dt = ld[task=="groupby" & script_recent==TRUE]
  .nrow=1e7; data="G1_1e7_1e2_0_0"; 
  .nrow=1e8; data="G1_1e8_1e2_0_0"; 
  .nrow=1e9; data="G1_1e9_1e2_0_0"; 
  .nrow=1e9; data="G1_1e9_2e0_0_0"; 
  .nrow=1e9; data="G1_1e9_1e1_0_0"; 
  timings=copy(dt); code=groupby.code; task="groupby"; .interactive=TRUE; colors=solution.colors; by.nsolutions=FALSE; cutoff="spark"; cutoff.after=0.2; fnam=NULL; path=NULL
  benchplot(.nrow=.nrow, data=data, timings=timings, code=code, colors=colors, cutoff=cutoff, .interactive=.interactive, by.nsolutions=by.nsolutions)
}
