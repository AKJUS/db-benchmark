---
title: "Single-node data aggregation benchmark"
output:
  html_document:
    self_contained: no
    includes:
      in_header: ga.html
---

This page aims to benchmark various database-like tools popular in open-source data science. It runs regularly against very latest versions of these packages and automatically updates. We provide this as a service to both developers of these packages and to users. We hope to add joins and updates with a focus on ordered operations which are hard to achieve in (unordered) SQL. We hope to add more solutions over time although the most interesting solutions seems to be not mature enough. See [README.md](https://github.com/h2oai/db-benchmark/blob/master/README.md) for detailed status.

We limit the scope to what can be achieved on a single machine. Laptop size memory (8GB) and server size memory (250GB) are in scope. Out-of-memory using local disk such as NVMe is in scope. Multi-node systems such as Spark running in single machine mode is in scope, too. Machines are getting bigger: EC2 X1 has 2TB RAM and 1TB NVMe disk is under $300. If you can perform the task on a single machine, then perhaps you should. To our knowledge, nobody has yet compared this software in this way and published results too.

We also include the syntax being timed alongside the timing. This way you can immediately see whether you are doing these tasks or not, and if the timing differences matter to you or not. A 10x difference may be irrelevant if that's just 1s vs 0.1s on your data size. The intention is that you click the tab for the size of data you have.

Because we have been asked many times to do so, the first task and initial motivation for this page, was to update the benchmark designed and run by [Matt Dowle](https://twitter.com/MattDowle) (creator of [data.table](https://github.com/Rdatatable/data.table)) in 2014 [here](https://github.com/Rdatatable/data.table/wiki/Benchmarks-%3A-Grouping). The methodology and reproducible code can be obtained there. Exact code of this report and benchmark script can be found at [h2oai/db-benchmark](https://github.com/h2oai/db-benchmark) created by [Jan Gorecki](https://github.com/jangorecki) funded by [H2O.ai](https://www.h2o.ai). In case of questions/feedback, feel free to file an issue there.  

```{r load_deps, include=FALSE}
# Rscript -e 'rmarkdown::render("index.Rmd", output_dir="public")' # has to be output_dir='public' as there is hardcode in benchplot for that path
knitr::opts_chunk$set(echo=FALSE, cache=FALSE)
library(data.table)
source("helpers.R")
source("benchplot.R") # also creates 'code' for groupby
fs = function(x) factor(x, levels=unique(x))
kk = knitr::kable
```

```{r exceptions, include=FALSE, eval=FALSE}
# CURRENTLY NOT USED
#exceptions = rbindlist(list(
#  data.table(solution = "pandas", version="0.23.4", task = "groupby", in_rows = 1e9, data=c("G1_1e9_1e2_0_0"), comment = "lack of memory to read csv")#,
    #data.table(solution = "pandas", version="0.23.4", task = "join", in_rows = 1e9, data=c("X1e9_2c-Y1e9_2c"), comment = "lack of memory"),
  #data.table(solution = "dplyr", version="0.7.99.9000", task = "join", in_rows = 1e9, data=c("X1e9_2c-Y1e9_2c"), comment = "Cannot allocate memory"),
  #data.table(solution = "pydatatable", version="0.6.0", task = "join", in_rows = c(1e7,1e8,1e9), data=c("X1e7_2c-Y1e7_2c","X1e8_2c-Y1e8_2c","X1e9_2c-Y1e9_2c"), comment = "not yet implemented")
#))
```

```{r load_data, include=FALSE}
# all timings
DT = read_timing("time.csv", raw=TRUE)
DT = DT[solution%in%c("data.table","dplyr","pandas","pydatatable","spark","dask","juliadf")] # modin not yet support grouping
dt = DT[!is.na(batch)][in_rows %in% c(1e7, 1e8, 1e9)] # filter out 1e6, and eventually others
if (!nrow(dt)) stop("There are no timings for defined list of solutions and data sizes")
recent = dt[, .(last_batch=max(batch, na.rm=TRUE)), .(task, solution, data)]
dt = dt[recent, on=c("task","solution","data","batch"="last_batch"), nomatch=NULL]
dt = dt[order(solution)]
```

## Groupby {.tabset .tabset-fade .tabset-pills}

```{r filter_task, include=FALSE}
dt = dt[task=="groupby"]
by_data = function(dt, .in_rows, .task) {
  dt = dt[in_rows==.in_rows]
  if (!nrow(dt)) return(invisible(NULL))
  decompose_dataname = function(x, task) {
    if (task=="groupby") {
      y = strsplit(as.character(x), "_", fixed = TRUE)[[1L]]
      lapply(y[-1L], as.numeric)
    } else {
      stop("no other task defined for decompose_dataname")
    }
  }
  dt[run==1L, dcast(.SD, fs(data)+fs(question) ~ fs(solution), value.var="time_sec")
     ][, c("rows","q1_grp.size","NA_pct","sorted") := decompose_dataname(data, .task), by=1:length(data)
       ][question=="sum v1 by id1", "data":=sprintf("[%s](%s/%s.png)", data, "plots", gsub("G1_", "groupby.", data, fixed=TRUE))
         ][question!="sum v1 by id1", "data":=""
           ] -> tmp
  setcolorder(tmp, c("data","rows","q1_grp.size","NA_pct","sorted"))
  kk(tmp)
}
```

Below timings are presented for a single dataset case having random order, no NAs (missing values) and particular cardinality factor (group size question 1 `k=100`). To see timings for first run in other cases scroll down to summary table.

### 0.5GB

```{r o_groupby1, echo=FALSE}
for (fn in c("1e7_1e2_0_0","1e7_1e1_0_0","1e7_2e0_0_0","1e7_1e2_0_1")) {
  fnam = paste0("groupby.",fn,".png")
  unlink(fnam)
  benchplot(1e7, data=paste0("G1_",fn), timings=dt, code=groupby.code, colors=solution.colors, fnam=fnam, cutoff="data.table")
}
```
![](public/plots/groupby.1e7_1e2_0_0.png)
&nbsp;  
&nbsp;
```{r o_groupby1_summary, echo=FALSE}
by_data(dt, 1e7, "groupby")
```

### 5GB

```{r o_groupby2, echo=FALSE}
for (fn in c("1e8_1e2_0_0","1e8_1e1_0_0","1e8_2e0_0_0","1e8_1e2_0_1")) {
  fnam = paste0("groupby.",fn,".png")
  unlink(fnam)
  benchplot(1e8, data=paste0("G1_",fn), timings=dt, code=groupby.code, colors=solution.colors, fnam=fnam, cutoff="data.table")
}
```
![](public/plots/groupby.1e8_1e2_0_0.png)
&nbsp;  
&nbsp;
```{r o_groupby2_summary, echo=FALSE}
by_data(dt, 1e8, "groupby")
```

### 50GB {.active}

```{r o_groupby3, echo=FALSE}
for (fn in c("1e9_1e2_0_0","1e9_1e1_0_0","1e9_2e0_0_0","1e9_1e2_0_1")) {
  fnam = paste0("groupby.",fn,".png")
  unlink(fnam)
  benchplot(1e9, data=paste0("G1_",fn), timings=dt, code=groupby.code, colors=solution.colors, fnam=fnam, cutoff="data.table")
}
```
![](public/plots/groupby.1e9_1e2_0_0.png)
&nbsp;  
&nbsp;
```{r o_groupby3_summary, echo=FALSE}
by_data(dt, 1e9, "groupby")
```

## Hardware configuration

```{r logs, echo=FALSE}
lg = fread("logs.csv")[task=="groupby" & action!="skip"]
recent_batch = lg[, .(last_batch=max(batch, na.rm=TRUE)), .(task, solution, data)]
recent_lg = lg[recent_batch, on=c("task","solution","data","batch"="last_batch"), nomatch=NULL]
```

```{r hardware, echo=FALSE}
if (uniqueN(recent_lg, by="nodename") > 1) {
  warning("presented timings were gathered on multiple machines")
} else {
  as.data.table(na.omit(fread("nodenames.csv")[unique(recent_lg$nodename), on="nodename", t(.SD)]), keep.rownames=TRUE)[rn!="nodename", .(Component=rn, Value=V1)][, kk(.SD)]
}
#kB_to_GB = function(x) {
#  nx = nchar(x)
#  if (!identical(substring(x, nx-1, nx), "kB")) stop("unexpected units of memory returned from 'grep ^MemTotal /proc/meminfo', expects 'kB'")
#  sprintf("%.2f GB", as.numeric(trimws(gsub("kB", "", x)))/1024^2)
#}
#fread(
#  cmd="lscpu | grep '^Model name:\\|^CPU(s):' && grep ^MemTotal /proc/meminfo",
#  sep=":", header=FALSE
#)[V1=="MemTotal", `:=`(V1="Memory", V2=kB_to_GB(V2))
#  ][, .(Component=V1, Value=V2)
#    ][, kk(.SD)]
```

------

```{r total_task_time, include=FALSE}
unfinished = recent_lg[, .N==1L, .(batch, solution, task, data)][, setNames(V1, solution)]
if (any(unfinished)) {
  warning(sprintf("Missing solution finish timestamp in logs.csv for '%s' (still running or killed): %s", "groupby", paste(names(unfinished)[unfinished], collapse=", ")))
  hours_took = "at least "
} else hours_took = ""
hours_took = paste0(hours_took, recent_lg[, .(sec_diff = timestamp[action=="finish"] - timestamp[action=="start"]), .(solution, task, data)][, round(sum(sec_diff)/60/60, 1)])
```

Benchmark run took around `r hours_took` hours.  

Report was generated on: `r format(Sys.time(), usetz=TRUE)`.
